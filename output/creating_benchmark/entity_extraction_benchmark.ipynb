{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from litellm import completion\n",
    "from dotenv import load_dotenv\n",
    "from tqdm import tqdm\n",
    "import textwrap\n",
    "from GrobidArticleExtractor import GrobidArticleExtractor\n",
    "from langchain.prompts import PromptTemplate\n",
    "from entity_extraction import ChatOpenRouter, parse_pdf, get_model_output, process_and_save_output, create_chain, run_chain_on_small_chunks, process_and_save_output_multiple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "OPENROUTER_API_KEY = os.environ[\"OPENROUTER_API_KEY\"] \n",
    "GROBID_SERVER_URL = os.environ[\"GROBID_SERVER_URL\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grobid_client = GrobidArticleExtractor(GROBID_SERVER_URL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_text = parse_pdf('data/Lin_2023_12pg.pdf', grobid_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_prompt = PromptTemplate(\n",
    "    input_variables=[\"neuroscience_text\"],\n",
    "    template=textwrap.dedent(\"\"\"\\\n",
    "    **Background**\n",
    "    You are a highly skilled neuroscience expert with extensive experience in named entity recognition and research publication entity annotation.\n",
    "    \n",
    "    **Task**\n",
    "    Meticulously extract and classify all relevant entities into the most appropriate and specific category from the provided neuroscience text. \n",
    "    The list of entities extracted should be exhaustive and comprehensive. You should identify and label all entities, including duplicates.                                                             \n",
    "    Please ensure that all entities are accurately identified and classified according to their role within the neuroscience domain. \n",
    "    Be precise with the start and end character positions.\n",
    "    \n",
    "    **Output Format**\n",
    "    The final output should be formatted as a training-ready JSON object suitable for spaCy's Named Entity Recognition (NER) training.\n",
    "    Each object in the 'entities' list should contain the 'entity', 'start', 'end', and 'label' keys.\n",
    "    All entity labels must be in UPPERCASE and use underscores for spaces (e.g., 'BRAIN_REGION' not 'brain region').\n",
    "    Return the result in the following JSON format:\n",
    "    ```json\n",
    "    {{\n",
    "      \"text\": \"<original_input_text>\",\n",
    "      \"entities\": [\n",
    "        {{\n",
    "          \"entity\": \"<surface_form>\",\n",
    "          \"start\": <start_index>,\n",
    "          \"end\": <end_index>,\n",
    "          \"label\": \"<ENTITY_TYPE\",\n",
    "          \n",
    "        }},\n",
    "        ...\n",
    "      ]\n",
    "    }}\n",
    "    ```\n",
    "                                                   \n",
    "     **Input Text:** {neuroscience_text}\n",
    "    \"\"\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running NER on sections: 100%|██████████| 10/10 [10:53<00:00, 65.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 30 outputs to lin_openai_gpt-4o-mini_20250507_192255.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "llm_gpt_4o_mini = ChatOpenRouter(model_name='openai/gpt-4o-mini')\n",
    "ner_chain_gpt = create_chain(llm_gpt_4o_mini, ner_prompt)\n",
    "lin_output_gpt = run_chain_on_small_chunks(lin_text, ner_chain_gpt)\n",
    "lin_formatted_output_gpt = process_and_save_output_multiple(lin_output_gpt, file_prefix = 'lin', prompt = ner_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running NER on sections: 100%|██████████| 10/10 [04:27<00:00, 26.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 30 outputs to lin_google_gemini-2.0-flash-001_20250507_192808.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "llm_gemini_20_flash = ChatOpenRouter(model_name='google/gemini-2.0-flash-001')\n",
    "ner_chain_gemini = create_chain(llm_gemini_20_flash, ner_prompt)\n",
    "lin_output_gemini = run_chain_on_small_chunks(lin_text, ner_chain_gemini)\n",
    "lin_formatted_output_gemini = process_and_save_output_multiple(lin_output_gemini, file_prefix = 'lin', prompt = ner_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running NER on sections: 100%|██████████| 10/10 [34:40<00:00, 208.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No JSON block found in section 11.\n",
      "Warning: No JSON block found in section 28.\n",
      "Saved 30 outputs to lin_deepseek_deepseek-chat-v3-0324:free_20250507_200333.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "llm_deepseek_v3 = ChatOpenRouter(model_name='deepseek/deepseek-chat-v3-0324:free')\n",
    "ner_chain_deepseek = create_chain(llm_deepseek_v3, ner_prompt)\n",
    "lin_output_deepseek = run_chain_on_small_chunks(lin_text, ner_chain_deepseek)\n",
    "lin_formatted_output_deepseek = process_and_save_output_multiple(lin_output_deepseek, file_prefix = 'lin', prompt = ner_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running NER on sections: 100%|██████████| 10/10 [15:25<00:00, 92.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 30 outputs to lin_anthropic_claude-3.7-sonnet_20250507_214630.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "llm_claude_37_sonnet = ChatOpenRouter(model_name='anthropic/claude-3.7-sonnet')\n",
    "ner_chain_claude = create_chain(llm_claude_37_sonnet, ner_prompt)\n",
    "lin_output_claude = run_chain_on_small_chunks(lin_text, ner_chain_claude)\n",
    "lin_formatted_output_claude = process_and_save_output_multiple(lin_output_claude, file_prefix = 'lin', prompt = ner_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_qwen_32b = ChatOpenRouter(model_name='qwen/qwen3-32b')\n",
    "ner_chain_qwen = create_chain(llm_qwen_32b, ner_prompt)\n",
    "lin_output_qwen = run_chain_on_small_chunks(lin_text, ner_chain_qwen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
